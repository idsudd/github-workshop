{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#workshop-orbitar-jupyter-y-aterrizar-en-la-tierra","title":"[Workshop] Orbitar Jupyter y Aterrizar en la Tierra","text":""},{"location":"#un-viaje-en-github-hacia-la-ciencia-de-datos-practica-y-colaborativa","title":"Un viaje en Github hacia la Ciencia de Datos Pr\u00e1ctica y Colaborativa.","text":"<p>El curso es una intensiva sesi\u00f3n de trabajo dise\u00f1ada para transformar la manera en que los estudiantes abordan la Ciencia de Datos, pasando de proyectos solitarios en Jupyter Notebook a un enfoque m\u00e1s colaborativo y pr\u00e1ctico, listo para integrarse en entornos de software reales.   Comenzando  Clases</p>"},{"location":"introduccion/","title":"Introduccion","text":"<p>Note</p> <p>I've led this short workshop as part of Summer School of UDD CICS. I will soon compile the material here.</p>"},{"location":"introduccion/#workshop-orbitar-jupyter-y-aterrizar-en-la-tierra-un-viaje-en-github-hacia-la-ciencia-de-datos-practica-y-colaborativa","title":"[Workshop] Orbitar Jupyter y Aterrizar en la Tierra: un viaje en Github hacia la Ciencia de Datos Pr\u00e1ctica y Colaborativa.","text":""},{"location":"introduccion/#resumen","title":"Resumen","text":"<p>El curso es una intensiva sesi\u00f3n de trabajo dise\u00f1ada para transformar la manera en que los estudiantes abordan la Ciencia de Datos: pasando de proyectos solitarios en Jupyter Notebook a un enfoque m\u00e1s colaborativo y pr\u00e1ctico, listo para integrarse en entornos de software reales.</p> <p>Se comienza con una introducci\u00f3n r\u00e1pida a la Ciencia de Datos, enfatizando la importancia de estructuras de proyectos estandarizadas. Se explorar\u00e1 c\u00f3mo Jupyter puede ser la puerta de entrada para an\u00e1lisis complejos, experimentaci\u00f3n y desarrollo de productos de datos. </p> <p>Luego se aborda c\u00f3mo estructurar proyectos de Ciencia de Datos con metodolog\u00edas estandarizadas como Cookiecutter para asegurar que sean mantenibles, replicables y escalables, adecuados para colaboraci\u00f3n y uso en entornos de software real. No s\u00f3lo se pondr\u00e1 foco en el c\u00f3digo, sino tambi\u00e9n en como trabajar con datos y modelos de machine learning.</p> <p>A continuaci\u00f3n, se exploran las tecnolog\u00edas Git/GitHub, herramientas cruciales para el trabajo colaborativo. Los estudiantes aprenden sobre control de versiones (crear, clonar, commit, push, pull, branches), colaboraci\u00f3n efectiva y la automatizaci\u00f3n de flujos de trabajo (github actions).</p> <p>Tambi\u00e9n se introducen temas clave para generar proyectos estructurados y listos para ser compartidos o desplegados, tales como entornos virtuales, devops, integraci\u00f3n continua, colaboraci\u00f3n open source, templates y contenedores, con el objetivo de establecer un camino de aprendizaje sugerido para el futuro.</p>"},{"location":"introduccion/#requisitos","title":"Requisitos","text":"<ul> <li>Conocimiento b\u00e1sico de Python.</li> <li>Instalaci\u00f3n funcional del software Anaconda.</li> <li>Una cuenta de GitHub.</li> </ul>"},{"location":"introduccion/#material","title":"Material","text":"<ul> <li>Github Repositories List</li> <li>Template: Introduccion a Github</li> <li>Template: IDS Cookiecutter</li> <li>Hands-On ML</li> </ul>"},{"location":"introduccion/#introduccion","title":"Introduccion","text":""},{"location":"introduccion/#profesor","title":"Profesor","text":"<ul> <li>Subdirector de Alianzas con la Industria @  Instituto de Ciencia de Datos, Universidad del Desarrollo.</li> <li>Consultor Independiente: GeoVictoria - Defontana - Discolab - Subconscious.ai.</li> <li>Profesor en el Mag\u00edster de Data Science @ Universidad del Desarrollo.</li> <li>Ingeniero El\u00e9ctrico @ Universidad de Chile.</li> </ul> <p>Empresas con las que he trabajado en la construcci\u00f3n de alg\u00fan Producto de Datos</p>"},{"location":"introduccion/#ciencia-de-datos","title":"Ciencia de Datos","text":"<p>Ciencia de Datos es el estudio de extraer valor de los datos. Valor que puede ser en forma de insights (nuevas perspectivas) o conclusiones.</p> <p>Data Science in Context: Foundations, Challenges, Opportunities.</p> <p></p> <p>The AI Hierarchy of Needs (M\u00f3nica Rogati, Hackernoon)\u200b</p> <p>La triste realidad es que la mayor\u00eda de los proyectos de IA fracasan. Seg\u00fan una investigaci\u00f3n de Gartner, solo el 15% de las soluciones de IA implementadas para 2022 ser\u00e1n exitosas, y ser\u00e1n muchas menos las que crear\u00e1n un valor positivo en t\u00e9rminos de ROI.</p> <p>Why most AI implementations fail, and what enterprises can do to beat the odds\u200b.</p> <p></p> <p>MLOps: Why you Might Want to use Machine Learning</p>"},{"location":"introduccion/#necesidades","title":"Necesidades","text":"<p>La ejecuci\u00f3n de un proyecto de Ciencia de Datos aborda todo el proceso de resoluci\u00f3n de un problema: desde la recopilaci\u00f3n y el procesamiento de datos, hasta el dise\u00f1o del mejor m\u00e9todo para resolver el problema y la implementaci\u00f3n de una soluci\u00f3n.  Los problemas y los conjuntos de datos provienen de entornos realistas similares a los que nos podr\u00edamos encontrar en la industria, la academia o el gobierno. Por lo tanto, los proyectos por lo menos incluir\u00e1n: </p> <ul> <li>Formulaci\u00f3n de una pregunta para ser respondida por los datos.</li> <li>Limpieza y procesamiento de datos.</li> <li>Elegir y aplicar un modelo y/o m\u00e9todo anal\u00edtico adecuado al problema.</li> <li>Y comunicar los resultados a una audiencia no t\u00e9cnica.</li> </ul> <p>Entre los desaf\u00edos que algo as\u00ed plantea, encontramos que:</p> <ul> <li>Se debe atender el ciclo completo del proyecto: no s\u00f3lo es mostrar el bello resultado final.</li> <li>En la mayor\u00eda de los casos trabajaremos en equipos, nunca solos.</li> <li>Ser\u00e1 necesario responder con facilidad y rapidez por cada parte del proceso, ya que un grupo de investigadores/compa\u00f1eros de equipo/stakeholders estar\u00e1n presionando.</li> <li>Todo esto se desarrolla programando.</li> </ul> <p>\u00a1La calidad del c\u00f3digo es muy importante! En Ciencia de Datos todo se reduce a prolijidad y reproducibilidad. La forma m\u00e1s f\u00e1cil de alcanzar eso es mediante una estructura para el c\u00f3digo o un cierto dise\u00f1o del proyecto. Debemos empezar con una estructura limpia y mantenerla viva en todo el ciclo del proyecto.</p>"},{"location":"introduccion/#por-que-es-necesario-esta-metodologia","title":"Por qu\u00e9 es necesario esta metodolog\u00eda","text":""},{"location":"introduccion/#el-mundo-te-lo-agradecera","title":"El mundo te lo agradecer\u00e1","text":"<ul> <li>Ser\u00e1 mucho m\u00e1s f\u00e1cil colaborar en equipo.</li> <li>Se podr\u00e1 aprender m\u00e1s al analizar de forma m\u00e1s f\u00e1cil el proceso que se sigue al construir proyectos.</li> <li>Todos podremos sentirnos m\u00e1s confiados sobre la veracidad de las conclusiones a las que lleguen los proyectos.</li> </ul>"},{"location":"introduccion/#tu-te-lo-agradeceras","title":"T\u00fa te lo agradecer\u00e1s","text":"<ul> <li>\u00bfHab\u00eda que usar <code>plot_figures.py.old</code> o era <code>new_figures01.py</code> o <code>new_figures01_updated.py</code>?</li> <li>\u00bfHab\u00eda que hacer el merge con la columna X antes de empezar o eso quedaba dentro de alguno de los notebooks</li> <li>\u00bfCu\u00e1l notebook iba primero, era \u201cprocesar datos\u201d o \u201climpiar datos\u201d?</li> <li>\u00bfDe d\u00f3nde fue que baj\u00e9 los shapefiles para dibujar los mapas?</li> </ul>"},{"location":"introduccion/#cookiecutter","title":"Cookiecutter","text":""},{"location":"introduccion/#estructura","title":"Estructura","text":"<p>Est\u00e1 basada en Cookiecutter Data Science pero simplifacada en el Template IDS Cookiecutter.</p> <pre><code>\u251c\u2500\u2500 LICENSE\n\u251c\u2500\u2500 README.md          &lt;- The top-level README for developers using this project.\n\u251c\u2500\u2500 data\n\u2502   \u251c\u2500\u2500 external       &lt;- Data from third party sources.\n\u2502   \u251c\u2500\u2500 interim        &lt;- Intermediate data that has been transformed.\n\u2502   \u251c\u2500\u2500 processed      &lt;- The final, canonical data sets for modeling.\n\u2502   \u2514\u2500\u2500 raw            &lt;- The original, immutable data dump.\n\u2502\n\u251c\u2500\u2500 models             &lt;- Trained and serialized models, model predictions, or model summaries\n\u2502\n\u251c\u2500\u2500 notebooks          &lt;- Jupyter notebooks. Naming convention is a number (for ordering),\n\u2502                         the creator's initials, and a short `-` delimited description, e.g.\n\u2502                         `1.0-jqp-initial-data-exploration`.\n\u2502\n\u251c\u2500\u2500 references         &lt;- Data dictionaries, manuals, and all other explanatory materials.\n\u2502\n\u251c\u2500\u2500 reports            &lt;- Generated analysis as HTML, PDF, LaTeX, etc.\n\u2502   \u2514\u2500\u2500 figures        &lt;- Generated graphics and figures to be used in reporting\n\u2502\n\u2502\n\u251c\u2500\u2500 src                &lt;- Source code for use in this project.\n\u2502   \u251c\u2500\u2500 __init__.py    &lt;- Makes src a Python module\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 data           &lt;- Scripts to download or generate data\n\u2502   \u2502   \u2514\u2500\u2500 make_dataset.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 features       &lt;- Scripts to turn raw data into features for modeling\n\u2502   \u2502   \u2514\u2500\u2500 build_features.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 models         &lt;- Scripts to train models and then use trained models to make\n\u2502   \u2502   \u2502                 predictions\n\u2502   \u2502   \u251c\u2500\u2500 predict_model.py\n\u2502   \u2502   \u2514\u2500\u2500 train_model.py\n\u2502   \u2502\n\u2502   \u2514\u2500\u2500 visualization  &lt;- Scripts to create exploratory and results oriented visualizations\n\u2502       \u2514\u2500\u2500 visualize.py\n\u251c\u2500\u2500 requirements.txt   &lt;- The requirements file for reproducing the analysis environment, e.g. generated with `pip freeze &gt; requirements.txt`\n</code></pre>"},{"location":"introduccion/#los-datos-son-inmutables","title":"Los datos son inmutables","text":"<ul> <li>Nunca se debe editar la data cruda (raw data).<ul> <li>Nunca se debe editar manualmente.<ul> <li>Nunca se debe editar en Excel.</li> </ul> </li> </ul> </li> <li>Nunca se debe sobre-escribir raw data.</li> <li>No se debe guardar m\u00faltiples versiones de un archivo de raw data</li> <li>El c\u00f3digo que se escriba debe mover la data cruda por medio de un pipeline hacia el an\u00e1lisis final.</li> <li>Cualquier persona deber\u00eda poder reproducir los resultados s\u00f3lo teniendo la carpeta <code>data/raw</code> y el c\u00f3digo en la carpeta <code>src</code>.</li> <li>Si los datos son inmutables entonces no necesita tener el mismo control de versiones que el c\u00f3digo. Por defecto el directorio data deber\u00eda estar incluido en el archivo <code>.gitignore</code>.</li> </ul>"},{"location":"introduccion/#los-notebooks-son-para-exploracion-y-comunicacion","title":"Los notebooks son para exploraci\u00f3n y comunicaci\u00f3n","text":"<ul> <li>Son muy buenos para an\u00e1lisis exploratorio pero no tan buenos para reproducir de forma efectiva ese an\u00e1lisis.</li> <li>Se sugiere trabajar en carpetas dentro del directorio notebooks.</li> <li>Se sugiere seguir una convenci\u00f3n para nombrar los archivos: <code>&lt;step&gt;-&lt;ghuser&gt;-&lt;description&gt;.ipynb</code>. Ejemplo: <code>03-aastroza-visualize-distributions.ipynb</code></li> <li>Hay que hacer refactorizaciones de las partes claves. No se debe repetir el c\u00f3digo de la misma tarea en diferentes notebooks. Si el c\u00f3digo es \u00fatil, escribanlo siempre a la carpeta <code>src</code>.</li> <li>Por ejemplo: si es una tarea de preprocesamiento de datos, hay que poner el pipeline en <code>src/data/make_dataset.py</code> y cargar datos desde <code>data/interim</code>. </li> </ul>"},{"location":"introduccion/#gitgithub","title":"Git/Github","text":"<p>Aprenderemos Github usando este Template. Hay que abrir este enlace y seguir las instrucciones.</p> <p>Git es un software de control de versiones dise\u00f1ado por Linus Torvalds, pensando en la eficiencia, la confiabilidad y compatibilidad del mantenimiento de versiones de aplicaciones cuando estas tienen un gran n\u00famero de archivos de c\u00f3digo fuente. Su prop\u00f3sito es llevar registro de los cambios en archivos de computadora incluyendo coordinar el trabajo que varias personas realizan sobre archivos compartidos en un repositorio de c\u00f3digo.</p> <p>Git en Wikipedia</p> <p></p> <p>Norman Perrin, Introducci\u00f3n a Git y Github</p> <p></p> <p>Understanding the GitHub flow</p> <p>Algunos tips de Git for Data Science:</p>"},{"location":"introduccion/#no-agregues-los-datasets","title":"No agregues los datasets","text":"<p>Git es un sistema de control de versiones dise\u00f1ado para servir a los desarrolladores de software. Cuenta con excelentes herramientas para manejar el c\u00f3digo fuente y otros contenidos relacionados como configuraci\u00f3n, dependencias, documentaci\u00f3n. No est\u00e1 pensado para datos de entrenamiento. Punto. Git es solo para c\u00f3digo.</p> <p>En el desarrollo de software, el c\u00f3digo es rey y todo lo dem\u00e1s sirve al c\u00f3digo. En la ciencia de datos, esto ya no es el caso y existe una dualidad entre datos y c\u00f3digo. No tiene sentido que el c\u00f3digo dependa de los datos tanto como no tiene sentido que los datos dependan del c\u00f3digo. Deben estar desacoplados y aqu\u00ed es donde el modelo de desarrollo de software centrado en el c\u00f3digo te falla. Git no deber\u00eda ser el punto central de verdad para un proyecto de ciencia de datos.</p> <p>Hay extensiones como LFS que se refieren a conjuntos de datos externos desde un repositorio git. Aunque cumplen un prop\u00f3sito y resuelven algunos de los l\u00edmites t\u00e9cnicos (tama\u00f1o, velocidad), no resuelven el problema central de una mentalidad de desarrollo de software centrada en el c\u00f3digo arraigada en git.</p> <p>Siempre tendr\u00e1s conjuntos de datos flotando en tu directorio local, sin embargo. Es bastante f\u00e1cil agregarlos accidentalmente al escenario y hacer un commit de ellos si no tienes cuidado. La forma correcta de asegurarte de que no necesitas preocuparte por los conjuntos de datos con git es usar el archivo de configuraci\u00f3n .gitignore. Agrega tus conjuntos de datos o la carpeta de datos a la configuraci\u00f3n y no mires atr\u00e1s.</p> <p>Ejemplo:</p> <pre><code># ignore archives\n*.zip\n*.tar\n*.tar.gz\n*.rar\n\n# ignore dataset folder and subfolders\ndata/\n</code></pre>"},{"location":"introduccion/#no-agregues-tus-passwordskeys","title":"No agregues tus passwords/keys","text":"<p>Esto deber\u00eda ser obvio, pero los constantes errores en el mundo real nos demuestran que no lo es. No importa si el repositorio es privado. En ninguna circunstancia se debe hacer un commit de ning\u00fan nombre de usuario, contrase\u00f1a, token de API, c\u00f3digo clave, certificados TLS, o cualquier otro dato sensible en git.</p> <p>Incluso los repositorios privados son accesibles por m\u00faltiples cuentas y tambi\u00e9n se clonan en m\u00faltiples m\u00e1quinas locales. Esto le da al hipot\u00e9tico atacante exponencialmente m\u00e1s objetivos. Recuerda que los repositorios privados tambi\u00e9n pueden volverse p\u00fablicos en alg\u00fan momento.</p> <p>Desacopla tus secretos de tu c\u00f3digo y p\u00e1salos usando el entorno en su lugar. Para Python, puedes usar el com\u00fan archivo .env, que contiene las variables de entorno, y el archivo .gitignore, que asegura que el archivo .env no se env\u00ede al repositorio remoto de git. Es una buena idea tambi\u00e9n proporcionar el .env.template para que otros sepan qu\u00e9 tipo de variables de entorno espera el sistema.</p> <p>.env:</p> <p><code>API_TOKEN=98789fsda789a89sdafsa9f87sda98f7sda89f7</code></p> <p>.env.template:</p> <p><code>API_TOKEN=</code></p> <p>.gitignore:</p> <pre><code>.env\n</code></pre> <p>hello.py:</p> <pre><code>from dotenv import load_dotenv\nload_dotenv()\napi_token = os.getenv('API_TOKEN')\n</code></pre> <p>Esto todav\u00eda requiere algo de copiar y pegar manualmente para cualquiera que clone el repositorio por primera vez. Para una configuraci\u00f3n m\u00e1s avanzada, hay herramientas encriptadas y con acceso restringido que pueden compartir secretos a trav\u00e9s del entorno, como Doppler</p> <p>Note</p> <p>Si ya has enviado tus secretos al repositorio remoto, no intentes arreglar la situaci\u00f3n simplemente borr\u00e1ndolos. Es demasiado tarde ya que git est\u00e1 dise\u00f1ado para ser inmutable. Una vez que el gato est\u00e1 fuera de la bolsa, la \u00fanica estrategia v\u00e1lida es cambiar las contrase\u00f1as o desactivar los tokens.</p>"},{"location":"introduccion/#realiza-commits-pequenos-con-descripciones-claras","title":"Realiza commits peque\u00f1os con descripciones claras","text":"<p>Los usuarios inexpertos a menudo caen en la trampa de hacer commits enormes con descripciones sin sentido. Una buena regla general para cualquier commit en git es que solo debe hacer una cosa. Arreglar un bug, no tres. Resolver un problema, no doce. Recuerda que los problemas a menudo pueden dividirse en partes m\u00e1s peque\u00f1as tambi\u00e9n. Cuanto m\u00e1s peque\u00f1o puedas hacerlo, mejor.</p> <p>La raz\u00f3n por la que usas el control de versiones es para que otra persona pueda entender lo que ha sucedido en el pasado. Si tu commit arregla doce bugs y la descripci\u00f3n dice \"Modelo arreglado\", su valor es cercano a cero dos meses despu\u00e9s. El commit solo debe hacer una cosa y solo una cosa. La descripci\u00f3n debe comunicar lo que esa cosa fue. No necesitas hacer descripciones extensas si los commits son peque\u00f1os. De hecho, \u00a1una descripci\u00f3n larga para un mensaje de commit implica que el commit es demasiado grande y deber\u00edas dividirlo en partes m\u00e1s peque\u00f1as!</p> <p>Ejemplo de un mal repositorio</p> <p></p> <p>Ejemplo de un buen repositorio</p> <p></p>"},{"location":"introduccion/#no-le-tengas-miedo-a-las-ramas-y-pull-requests","title":"No le tengas miedo a las ramas y pull requests","text":"<p>El uso de ramas y, en especial, de pull requests son t\u00e9cnicas ligeramente m\u00e1s avanzadas y no son del agrado de todos, pero si tu proyecto de ciencia de datos est\u00e1 maduro, en producci\u00f3n y constantemente manejado por muchas personas diferentes, los pull requests podr\u00edan ser justo lo que falta en tu proceso.</p> <p>Cuando creas un nuevo repositorio git, este comienza con una \u00fanica rama llamada main (o master). La rama main se considera como la verdad central. Crear ramas significa que te desviar\u00e1s temporalmente para crear una nueva caracter\u00edstica o una correcci\u00f3n a una antigua. Mientras tanto, alguien m\u00e1s puede trabajar en paralelo en su propia rama. Esto se conoce com\u00fanmente como flujo de trabajo de rama de caracter\u00edsticas.</p> <p></p> <p>Git for Data Science</p> <p>La idea con las ramas es eventualmente fusionarse de nuevo a la rama main y actualizar la verdad central. Aqu\u00ed es donde entran en juego los pull requests. Al resto del mundo no le importan tus commits en tu propia rama, pero fusionarse a main es cuando tu rama se convierte en la \u00faltima verdad. Ese es el momento de hacer un pull request.</p> <p>Los pull requests no son un concepto de git, sino de GitHub. Son una solicitud para hacer de tu rama la nueva verdad central. Mediante el pull request, otros usuarios revisar\u00e1n tus cambios antes de que se les permita convertirse en la nueva verdad central. GitHub ofrece excelentes herramientas para hacer comentarios, sugerir modificaciones, se\u00f1alar aprobaciones y finalmente aplicar la fusi\u00f3n autom\u00e1ticamente.</p>"},{"location":"introduccion/#opcional-no-agregues-los-outputs-de-los-jupyter-notebooks","title":"[Opcional] No agregues los outputs de los Jupyter Notebooks","text":"<p>Los notebooks son geniales porque te permiten no solo almacenar c\u00f3digo, sino tambi\u00e9n los resultados de las celdas, como im\u00e1genes, gr\u00e1ficos y tablas. El problema surge cuando haces commit y push del notebook con sus salidas a git.</p> <p>La forma en que los notebooks serializan todas las im\u00e1genes, gr\u00e1ficos y tablas no es atractiva. En lugar de archivos separados, codifica todo como sintaxis JSON en el archivo .ipynb. Esto confunde a git.</p> <p>Git piensa que la sintaxis JSON son igual de importantes que tu c\u00f3digo. Las tres l\u00edneas de c\u00f3digo que cambiaste se mezclan con las tres mil l\u00edneas que se cambiaron en la sintaxis JSON. Intentar comparar las dos versiones se vuelve in\u00fatil debido a todo el ruido adicional.</p> <p></p> <p>ReviewNB Blog</p> <p>Se vuelve a\u00fan m\u00e1s confuso si hemos cambiado algo de c\u00f3digo despu\u00e9s de que se generaron las salidas. Ahora el c\u00f3digo y las salidas que est\u00e1n almacenadas en el control de versiones ya no coinciden.</p> <p>Hay dos opciones a nuestra disposici\u00f3n:</p> <ul> <li>Puedes borrar manualmente las salidas desde el men\u00fa principal (Celdas -&gt; Toda la Salida -&gt; Borrar) antes de crear tu commit en git.</li> <li>Puedes configurar un hook de pre-commit para git que borre las salidas autom\u00e1ticamente.</li> </ul> <p>Trataremos de implementar esta opci\u00f3n #2, ya que los pasos manuales que necesitas recordar est\u00e1n destinados a fallar eventualmente.</p>"},{"location":"introduccion/#los-futuros-destinos-de-este-viaje","title":"Los futuros destinos de este viaje","text":""},{"location":"introduccion/#open-source","title":"Open Source","text":"<p>GitHub Open Source</p> <p>Making a pull request to an open-source project</p>"},{"location":"introduccion/#data-drift-concept-drift","title":"Data Drift / Concept Drift","text":"<p>Machine Learning in Production: Why You Should Care About Data and Concept Drift</p>"},{"location":"introduccion/#devopsmlopsllmops","title":"Devops/MLOps/LLMOps","text":"<p>Advanced Model Deployments (Hannes Hapke y Catherine Nelson)</p>"},{"location":"introduccion/#contenedores","title":"Contenedores","text":"<p>Modal</p>"},{"location":"introduccion/#otras-formas-de-contar-esta-historia","title":"Otras formas de contar esta historia","text":"<p>Nbdev</p>"},{"location":"introduccion/#bibliografia","title":"Bibliograf\u00eda","text":"<ul> <li>Github Skills</li> <li>Cookiecutter Data Science</li> <li>Git for Data Science</li> <li>Hands-On Machine Learning with Scikit-Learn, Keras &amp; TensorFlow</li> </ul>"},{"location":"welcome/","title":"Bienvenida","text":"<p>El curso se estructura de la siguiente forma:</p> <ul> <li>En la secci\u00f3n de Contenido est\u00e1 el texto de estudio.</li> <li>En la secci\u00f3n de Material est\u00e1n las actividades pr\u00e1cticas y ejemplos.</li> </ul>"},{"location":"welcome/#requisitos","title":"Requisitos","text":"<ul> <li>Conocimiento b\u00e1sico de Python.</li> <li>Una cuenta de GitHub.</li> <li>Actitud positiva ante el cambio.</li> </ul> <p>  Clases</p>"},{"location":"content/","title":"Contenido","text":""},{"location":"content/#motivacion","title":"Motivaci\u00f3n","text":"<ul> <li>\u00a1GitHub es la mejor red social del mundo!</li> <li>Todas las opciones avanzadas son gratis para profesores/estudiantes.</li> </ul>"},{"location":"content/challenges/","title":"Desaf\u00edos","text":"<p>La ejecuci\u00f3n de un proyecto de Ciencia de Datos aborda todo el proceso de resoluci\u00f3n de un problema: desde la recopilaci\u00f3n y el procesamiento de datos, hasta el dise\u00f1o del mejor m\u00e9todo para resolver el problema y la implementaci\u00f3n de una soluci\u00f3n.  Los problemas y los conjuntos de datos provienen de entornos realistas similares a los que nos podr\u00edamos encontrar en la industria, la academia o el gobierno. Por lo tanto, los proyectos por lo menos incluir\u00e1n: </p> <ul> <li>Formulaci\u00f3n de una pregunta para ser respondida por los datos.</li> <li>Limpieza y procesamiento de datos.</li> <li>Elegir y aplicar un modelo y/o m\u00e9todo anal\u00edtico adecuado al problema.</li> <li>Y comunicar los resultados a una audiencia no t\u00e9cnica.</li> </ul> <p>Entre los desaf\u00edos que algo as\u00ed plantea, encontramos que:</p> <ul> <li>Se debe atender el ciclo completo del proyecto: no s\u00f3lo es mostrar el bello resultado final.</li> <li>En la mayor\u00eda de los casos trabajaremos en equipos, nunca solos.</li> <li>Ser\u00e1 necesario responder con facilidad y rapidez por cada parte del proceso, ya que un grupo de investigadores/compa\u00f1eros de equipo/stakeholders estar\u00e1n presionando.</li> <li>Todo esto se desarrolla programando.</li> </ul> <p>\u00a1La calidad del c\u00f3digo es muy importante! En Ciencia de Datos todo se reduce a prolijidad y reproducibilidad. La forma m\u00e1s f\u00e1cil de alcanzar eso es mediante una estructura para el c\u00f3digo o un cierto dise\u00f1o del proyecto. Debemos empezar con una estructura limpia y mantenerla viva en todo el ciclo del proyecto.</p>"},{"location":"content/challenges/#por-que-es-necesario-esta-metodologia","title":"Por qu\u00e9 es necesario esta metodolog\u00eda","text":""},{"location":"content/challenges/#el-mundo-te-lo-agradecera","title":"El mundo te lo agradecer\u00e1","text":"<ul> <li>Ser\u00e1 mucho m\u00e1s f\u00e1cil colaborar en equipo.</li> <li>Se podr\u00e1 aprender m\u00e1s al analizar de forma m\u00e1s f\u00e1cil el proceso que se sigue al construir proyectos.</li> <li>Todos podremos sentirnos m\u00e1s confiados sobre la veracidad de las conclusiones a las que lleguen los proyectos.</li> </ul>"},{"location":"content/challenges/#tu-te-lo-agradeceras","title":"T\u00fa te lo agradecer\u00e1s","text":"<ul> <li>\u00bfHab\u00eda que usar <code>plot_figures.py.old</code> o era <code>new_figures01.py</code> o <code>new_figures01_updated.py</code>?</li> <li>\u00bfHab\u00eda que hacer el merge con la columna X antes de empezar o eso quedaba dentro de alguno de los notebooks</li> <li>\u00bfCu\u00e1l notebook iba primero, era \u201cprocesar datos\u201d o \u201climpiar datos\u201d?</li> <li>\u00bfDe d\u00f3nde fue que baj\u00e9 los shapefiles para dibujar los mapas?</li> </ul>"},{"location":"content/context/","title":"Contexto","text":""},{"location":"content/context/#ciencia-de-datos","title":"Ciencia de Datos","text":"<p>Ciencia de Datos es el estudio de extraer valor de los datos. Valor que puede ser en forma de insights (nuevas perspectivas) o conclusiones.</p> <p>Data Science in Context: Foundations, Challenges, Opportunities.</p> <p></p> <p>The AI Hierarchy of Needs (M\u00f3nica Rogati, Hackernoon)\u200b</p> <p>La triste realidad es que la mayor\u00eda de los proyectos de IA fracasan. Seg\u00fan una investigaci\u00f3n de Gartner, solo el 15% de las soluciones de IA implementadas para 2022 ser\u00e1n exitosas, y ser\u00e1n muchas menos las que crear\u00e1n un valor positivo en t\u00e9rminos de ROI.</p> <p>Why most AI implementations fail, and what enterprises can do to beat the odds\u200b.</p> <p></p> <p>MLOps: Why you Might Want to use Machine Learning</p>"},{"location":"content/context/#principios","title":"Principios","text":"<p>Es deseable tener una buena estrategia para desarrollar experimentos computacionales.<sup>1</sup></p> <ul> <li> <p>El principio rector fundamental es simple: Alguien que no est\u00e9 familiarizado con tu proyecto deber\u00eda poder mirar los archivos de tu computadora y entender en detalle lo que hiciste y por qu\u00e9. Este \"alguien\" podr\u00eda ser cualquiera de una variedad de personas: alguien que ley\u00f3 tu art\u00edculo publicado y quiere intentar reproducir tu trabajo, un colaborador que quiere entender los detalles de tus experimentos, un futuro estudiante que trabaje en tu laboratorio y quiera ampliar tu trabajo despu\u00e9s de que te hayas trasladado a un nuevo empleo, tu asesor de investigaci\u00f3n, que podr\u00eda estar interesado en entender tu trabajo o que podr\u00eda estar evaluando tus habilidades de investigaci\u00f3n. Sin embargo, lo m\u00e1s com\u00fan es que ese \"alguien\" seas t\u00fa. Dentro de unos meses, puede que no recuerdes en qu\u00e9 estabas trabajando cuando creaste un conjunto particular de archivos, o puede que no recuerdes las conclusiones que sacaste. Tendr\u00e1s que pasar tiempo reconstruyendo tus experimentos anteriores o perder las ideas que obtuviste de esos experimentos.</p> </li> <li> <p>Esto nos lleva al segundo principio, que en realidad es m\u00e1s como una versi\u00f3n de la Ley de Murphy: Todo lo que hagas, probablemente tendr\u00e1s que hacerlo de nuevo. Inevitablemente, descubrir\u00e1s alg\u00fan defecto en tu preparaci\u00f3n inicial de los datos que se est\u00e1n analizando, obtendr\u00e1s acceso a nuevos datos o decidir\u00e1s que la parametrizaci\u00f3n de un modelo particular no era lo suficientemente amplia. Esto significa que el experimento que hiciste la semana pasada, o incluso el conjunto de experimentos en los que has estado trabajando durante el \u00faltimo mes, probablemente necesitar\u00e1n ser repetidos. Si has organizado y documentado tu trabajo claramente, repetir el experimento con los nuevos datos o la nueva parametrizaci\u00f3n ser\u00e1 mucho, mucho m\u00e1s f\u00e1cil.</p> </li> </ul> <ol> <li> <p>Noble WS (2009) A Quick Guide to Organizing Computational Biology Projects. PLOS Computational Biology 5(7): e1000424. https://doi.org/10.1371/journal.pcbi.1000424\u00a0\u21a9</p> </li> </ol>"},{"location":"content/cookiecutter/","title":"Cookiecutter","text":""},{"location":"content/cookiecutter/#estructura","title":"Estructura","text":"<p>Est\u00e1 basada en Cookiecutter Data Science pero simplifacada en el Template IDS Cookiecutter.</p> <pre><code>\u251c\u2500\u2500 LICENSE\n\u251c\u2500\u2500 README.md          &lt;- The top-level README for developers using this project.\n\u251c\u2500\u2500 data\n\u2502   \u251c\u2500\u2500 external       &lt;- Data from third party sources.\n\u2502   \u251c\u2500\u2500 interim        &lt;- Intermediate data that has been transformed.\n\u2502   \u251c\u2500\u2500 processed      &lt;- The final, canonical data sets for modeling.\n\u2502   \u2514\u2500\u2500 raw            &lt;- The original, immutable data dump.\n\u2502\n\u251c\u2500\u2500 models             &lt;- Trained and serialized models, model predictions, or model summaries\n\u2502\n\u251c\u2500\u2500 notebooks          &lt;- Jupyter notebooks. Naming convention is a number (for ordering),\n\u2502                         the creator's initials, and a short `-` delimited description, e.g.\n\u2502                         `1.0-jqp-initial-data-exploration`.\n\u2502\n\u251c\u2500\u2500 references         &lt;- Data dictionaries, manuals, and all other explanatory materials.\n\u2502\n\u251c\u2500\u2500 reports            &lt;- Generated analysis as HTML, PDF, LaTeX, etc.\n\u2502   \u2514\u2500\u2500 figures        &lt;- Generated graphics and figures to be used in reporting\n\u2502\n\u2502\n\u251c\u2500\u2500 src                &lt;- Source code for use in this project.\n\u2502   \u251c\u2500\u2500 __init__.py    &lt;- Makes src a Python module\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 data           &lt;- Scripts to download or generate data\n\u2502   \u2502   \u2514\u2500\u2500 make_dataset.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 features       &lt;- Scripts to turn raw data into features for modeling\n\u2502   \u2502   \u2514\u2500\u2500 build_features.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 models         &lt;- Scripts to train models and then use trained models to make\n\u2502   \u2502   \u2502                 predictions\n\u2502   \u2502   \u251c\u2500\u2500 predict_model.py\n\u2502   \u2502   \u2514\u2500\u2500 train_model.py\n\u2502   \u2502\n\u2502   \u2514\u2500\u2500 visualization  &lt;- Scripts to create exploratory and results oriented visualizations\n\u2502       \u2514\u2500\u2500 visualize.py\n\u251c\u2500\u2500 requirements.txt   &lt;- The requirements file for reproducing the analysis environment, e.g. generated with `pip freeze &gt; requirements.txt`\n</code></pre>"},{"location":"content/cookiecutter/#los-datos-son-inmutables","title":"Los datos son inmutables","text":"<ul> <li>Nunca se debe editar la data cruda (raw data).<ul> <li>Nunca se debe editar manualmente.<ul> <li>Nunca se debe editar en Excel.</li> </ul> </li> </ul> </li> <li>Nunca se debe sobre-escribir raw data.</li> <li>No se debe guardar m\u00faltiples versiones de un archivo de raw data</li> <li>El c\u00f3digo que se escriba debe mover la data cruda por medio de un pipeline hacia el an\u00e1lisis final.</li> <li>Cualquier persona deber\u00eda poder reproducir los resultados s\u00f3lo teniendo la carpeta <code>data/raw</code> y el c\u00f3digo en la carpeta <code>src</code>.</li> <li>Si los datos son inmutables entonces no necesita tener el mismo control de versiones que el c\u00f3digo. Por defecto el directorio data deber\u00eda estar incluido en el archivo <code>.gitignore</code>.</li> </ul>"},{"location":"content/cookiecutter/#los-notebooks-son-para-exploracion-y-comunicacion","title":"Los notebooks son para exploraci\u00f3n y comunicaci\u00f3n","text":"<ul> <li>Son muy buenos para an\u00e1lisis exploratorio pero no tan buenos para reproducir de forma efectiva ese an\u00e1lisis.</li> <li>Se sugiere trabajar en carpetas dentro del directorio notebooks.</li> <li>Se sugiere seguir una convenci\u00f3n para nombrar los archivos: <code>&lt;step&gt;-&lt;ghuser&gt;-&lt;description&gt;.ipynb</code>. Ejemplo: <code>03-aastroza-visualize-distributions.ipynb</code></li> <li>Hay que hacer refactorizaciones de las partes claves. No se debe repetir el c\u00f3digo de la misma tarea en diferentes notebooks. Si el c\u00f3digo es \u00fatil, escribanlo siempre a la carpeta <code>src</code>.</li> <li>Por ejemplo: si es una tarea de preprocesamiento de datos, hay que poner el pipeline en <code>src/data/make_dataset.py</code> y cargar datos desde <code>data/interim</code>. </li> </ul>"},{"location":"content/cookiecutter/#refactorizando-codigo-en-modulos-compartidos","title":"Refactorizando c\u00f3digo en m\u00f3dulos compartidos","text":"<p>A medida que avance tu proyecto, querr\u00e1s refactorizar tu c\u00f3digo de manera que sea f\u00e1cil de compartir entre notebooks y scripts. Recomendamos crear un m\u00f3dulo en la carpeta {{ src.module_name }} que contenga el c\u00f3digo que usas en tu proyecto. Esta es una buena forma de asegurarte de que puedas usar el mismo c\u00f3digo en varios lugares sin tener que copiar y pegar.</p> <p>Dado que la estructura predeterminada es un paquete de Python y est\u00e1 instalado por defecto, puedes hacer lo siguiente para que ese c\u00f3digo est\u00e9 disponible dentro de un cuaderno de Jupyter.</p> <p>Primero, recomendamos activar la extensi\u00f3n autoreload. Esto har\u00e1 que Jupyter siempre vuelva al c\u00f3digo fuente del m\u00f3dulo en lugar de almacenarlo en cach\u00e9 en la memoria. Si tu cuaderno no refleja los \u00faltimos cambios realizados en un archivo .py, intenta reiniciar el kernel y aseg\u00farate de que autoreload est\u00e9 activado. Agregamos una celda al inicio del notebook con lo siguiente:</p> <pre><code>%load_ext autoreload\n%autoreload 2\n</code></pre> <p>Ahora todo tu c\u00f3digo deber\u00eda ser importable. Podr\u00edas usarlo import\u00e1ndolo de la siguiente manera:</p> <pre><code>from src.data import make_dataset\n\ndata = make_dataset()\n</code></pre> <p>Ahora deber\u00eda ser f\u00e1cil hacer cualquier refactorizaci\u00f3n que necesites para que tu c\u00f3digo sea m\u00e1s modular y reutilizable.</p>"},{"location":"content/git/","title":"Git","text":"<p>Aprenderemos Github usando este Template. Hay que abrir este enlace y seguir las instrucciones.</p> <p>Git es un software de control de versiones dise\u00f1ado por Linus Torvalds, pensando en la eficiencia, la confiabilidad y compatibilidad del mantenimiento de versiones de aplicaciones cuando estas tienen un gran n\u00famero de archivos de c\u00f3digo fuente. Su prop\u00f3sito es llevar registro de los cambios en archivos de computadora incluyendo coordinar el trabajo que varias personas realizan sobre archivos compartidos en un repositorio de c\u00f3digo.</p> <p>Git en Wikipedia</p> <p></p> <p>Norman Perrin, Introducci\u00f3n a Git y Github</p> <p></p> <p>Understanding the GitHub flow</p>"},{"location":"content/git/#por-que-es-importante","title":"Por qu\u00e9 es importante","text":"<p>Usar un software de control de versiones es invaluable para gestionar experimentos computacionales por tres razones:<sup>1</sup></p> <ul> <li> <p>Proporciona una forma de respaldo. </p> </li> <li> <p>Proporciona un registro hist\u00f3rico que puede ser \u00fatil para rastrear errores o entender resultados antiguos. T\u00edpicamente, un script o programa evolucionar\u00e1 a lo largo del curso de un proyecto. En lugar de almacenar muchas copias del script con nombres ligeramente diferentes, se conf\u00eda en el sistema de control de versiones para llevar un seguimiento de esas versiones. Si se necesita reproducir exactamente un experimento que se realiz\u00f3 hace tres meses, se puede usar el control de versiones para obtener una copia del estado del proyecto en ese momento.</p> </li> <li> <p>Es invaluable para proyectos colaborativos. El repositorio permite que los colaboradores trabajen simult\u00e1neamente en una colecci\u00f3n de archivos, incluidos scripts, documentaci\u00f3n o un borrador de manuscrito.</p> </li> </ul>"},{"location":"content/git/#consejos","title":"Consejos","text":"<p>Algunos tips de Git for Data Science:</p>"},{"location":"content/git/#no-agregues-los-datasets","title":"No agregues los datasets","text":"<p>Git es un sistema de control de versiones dise\u00f1ado para servir a los desarrolladores de software. Cuenta con excelentes herramientas para manejar el c\u00f3digo fuente y otros contenidos relacionados como configuraci\u00f3n, dependencias, documentaci\u00f3n. No est\u00e1 pensado para datos de entrenamiento. Punto. Git es solo para c\u00f3digo.</p> <p>En el desarrollo de software, el c\u00f3digo es rey y todo lo dem\u00e1s sirve al c\u00f3digo. En la ciencia de datos, esto ya no es el caso y existe una dualidad entre datos y c\u00f3digo. No tiene sentido que el c\u00f3digo dependa de los datos tanto como no tiene sentido que los datos dependan del c\u00f3digo. Deben estar desacoplados y aqu\u00ed es donde el modelo de desarrollo de software centrado en el c\u00f3digo te falla. Git no deber\u00eda ser el punto central de verdad para un proyecto de ciencia de datos.</p> <p>Hay extensiones como LFS que se refieren a conjuntos de datos externos desde un repositorio git. Aunque cumplen un prop\u00f3sito y resuelven algunos de los l\u00edmites t\u00e9cnicos (tama\u00f1o, velocidad), no resuelven el problema central de una mentalidad de desarrollo de software centrada en el c\u00f3digo arraigada en git.</p> <p>Siempre tendr\u00e1s conjuntos de datos flotando en tu directorio local, sin embargo. Es bastante f\u00e1cil agregarlos accidentalmente al escenario y hacer un commit de ellos si no tienes cuidado. La forma correcta de asegurarte de que no necesitas preocuparte por los conjuntos de datos con git es usar el archivo de configuraci\u00f3n .gitignore. Agrega tus conjuntos de datos o la carpeta de datos a la configuraci\u00f3n y no mires atr\u00e1s.</p> <p>Ejemplo:</p> <pre><code># ignore archives\n*.zip\n*.tar\n*.tar.gz\n*.rar\n\n# ignore dataset folder and subfolders\ndata/\n</code></pre>"},{"location":"content/git/#no-agregues-tus-passwordskeys","title":"No agregues tus passwords/keys","text":"<p>Esto deber\u00eda ser obvio, pero los constantes errores en el mundo real nos demuestran que no lo es. No importa si el repositorio es privado. En ninguna circunstancia se debe hacer un commit de ning\u00fan nombre de usuario, contrase\u00f1a, token de API, c\u00f3digo clave, certificados TLS, o cualquier otro dato sensible en git.</p> <p>Incluso los repositorios privados son accesibles por m\u00faltiples cuentas y tambi\u00e9n se clonan en m\u00faltiples m\u00e1quinas locales. Esto le da al hipot\u00e9tico atacante exponencialmente m\u00e1s objetivos. Recuerda que los repositorios privados tambi\u00e9n pueden volverse p\u00fablicos en alg\u00fan momento.</p> <p>Desacopla tus secretos de tu c\u00f3digo y p\u00e1salos usando el entorno en su lugar. Para Python, puedes usar el com\u00fan archivo .env, que contiene las variables de entorno, y el archivo .gitignore, que asegura que el archivo .env no se env\u00ede al repositorio remoto de git. Es una buena idea tambi\u00e9n proporcionar el .env.template para que otros sepan qu\u00e9 tipo de variables de entorno espera el sistema.</p> <p>.env:</p> <p><code>API_TOKEN=98789fsda789a89sdafsa9f87sda98f7sda89f7</code></p> <p>.env.template:</p> <p><code>API_TOKEN=</code></p> <p>.gitignore:</p> <pre><code>.env\n</code></pre> <p>hello.py:</p> <pre><code>from dotenv import load_dotenv\nload_dotenv()\napi_token = os.getenv('API_TOKEN')\n</code></pre> <p>Esto todav\u00eda requiere algo de copiar y pegar manualmente para cualquiera que clone el repositorio por primera vez. Para una configuraci\u00f3n m\u00e1s avanzada, hay herramientas encriptadas y con acceso restringido que pueden compartir secretos a trav\u00e9s del entorno, como Doppler</p> <p>Note</p> <p>Si ya has enviado tus secretos al repositorio remoto, no intentes arreglar la situaci\u00f3n simplemente borr\u00e1ndolos. Es demasiado tarde ya que git est\u00e1 dise\u00f1ado para ser inmutable. Una vez que el gato est\u00e1 fuera de la bolsa, la \u00fanica estrategia v\u00e1lida es cambiar las contrase\u00f1as o desactivar los tokens.</p>"},{"location":"content/git/#realiza-commits-pequenos-con-descripciones-claras","title":"Realiza commits peque\u00f1os con descripciones claras","text":"<p>Los usuarios inexpertos a menudo caen en la trampa de hacer commits enormes con descripciones sin sentido. Una buena regla general para cualquier commit en git es que solo debe hacer una cosa. Arreglar un bug, no tres. Resolver un problema, no doce. Recuerda que los problemas a menudo pueden dividirse en partes m\u00e1s peque\u00f1as tambi\u00e9n. Cuanto m\u00e1s peque\u00f1o puedas hacerlo, mejor.</p> <p>La raz\u00f3n por la que usas el control de versiones es para que otra persona pueda entender lo que ha sucedido en el pasado. Si tu commit arregla doce bugs y la descripci\u00f3n dice \"Modelo arreglado\", su valor es cercano a cero dos meses despu\u00e9s. El commit solo debe hacer una cosa y solo una cosa. La descripci\u00f3n debe comunicar lo que esa cosa fue. No necesitas hacer descripciones extensas si los commits son peque\u00f1os. De hecho, \u00a1una descripci\u00f3n larga para un mensaje de commit implica que el commit es demasiado grande y deber\u00edas dividirlo en partes m\u00e1s peque\u00f1as!</p> <p>Ejemplo de un mal repositorio</p> <p></p> <p>Ejemplo de un buen repositorio</p> <p></p>"},{"location":"content/git/#no-le-tengas-miedo-a-las-ramas-y-pull-requests","title":"No le tengas miedo a las ramas y pull requests","text":"<p>El uso de ramas y, en especial, de pull requests son t\u00e9cnicas ligeramente m\u00e1s avanzadas y no son del agrado de todos, pero si tu proyecto de ciencia de datos est\u00e1 maduro, en producci\u00f3n y constantemente manejado por muchas personas diferentes, los pull requests podr\u00edan ser justo lo que falta en tu proceso.</p> <p>Cuando creas un nuevo repositorio git, este comienza con una \u00fanica rama llamada main (o master). La rama main se considera como la verdad central. Crear ramas significa que te desviar\u00e1s temporalmente para crear una nueva caracter\u00edstica o una correcci\u00f3n a una antigua. Mientras tanto, alguien m\u00e1s puede trabajar en paralelo en su propia rama. Esto se conoce com\u00fanmente como flujo de trabajo de rama de caracter\u00edsticas.</p> <p></p> <p>Git for Data Science</p> <p>La idea con las ramas es eventualmente fusionarse de nuevo a la rama main y actualizar la verdad central. Aqu\u00ed es donde entran en juego los pull requests. Al resto del mundo no le importan tus commits en tu propia rama, pero fusionarse a main es cuando tu rama se convierte en la \u00faltima verdad. Ese es el momento de hacer un pull request.</p> <p>Los pull requests no son un concepto de git, sino de GitHub. Son una solicitud para hacer de tu rama la nueva verdad central. Mediante el pull request, otros usuarios revisar\u00e1n tus cambios antes de que se les permita convertirse en la nueva verdad central. GitHub ofrece excelentes herramientas para hacer comentarios, sugerir modificaciones, se\u00f1alar aprobaciones y finalmente aplicar la fusi\u00f3n autom\u00e1ticamente.</p>"},{"location":"content/git/#opcional-no-agregues-los-outputs-de-los-jupyter-notebooks","title":"[Opcional] No agregues los outputs de los Jupyter Notebooks","text":"<p>Los notebooks son geniales porque te permiten no solo almacenar c\u00f3digo, sino tambi\u00e9n los resultados de las celdas, como im\u00e1genes, gr\u00e1ficos y tablas. El problema surge cuando haces commit y push del notebook con sus salidas a git.</p> <p>La forma en que los notebooks serializan todas las im\u00e1genes, gr\u00e1ficos y tablas no es atractiva. En lugar de archivos separados, codifica todo como sintaxis JSON en el archivo .ipynb. Esto confunde a git.</p> <p>Git piensa que la sintaxis JSON son igual de importantes que tu c\u00f3digo. Las tres l\u00edneas de c\u00f3digo que cambiaste se mezclan con las tres mil l\u00edneas que se cambiaron en la sintaxis JSON. Intentar comparar las dos versiones se vuelve in\u00fatil debido a todo el ruido adicional.</p> <p></p> <p>ReviewNB Blog</p> <p>Se vuelve a\u00fan m\u00e1s confuso si hemos cambiado algo de c\u00f3digo despu\u00e9s de que se generaron las salidas. Ahora el c\u00f3digo y las salidas que est\u00e1n almacenadas en el control de versiones ya no coinciden.</p> <p>Hay dos opciones a nuestra disposici\u00f3n:</p> <ul> <li>Puedes borrar manualmente las salidas desde el men\u00fa principal (Celdas -&gt; Toda la Salida -&gt; Borrar) antes de crear tu commit en git.</li> <li>Puedes configurar un hook de pre-commit para git que borre las salidas autom\u00e1ticamente.</li> </ul> <p>Trataremos de implementar esta opci\u00f3n #2, ya que los pasos manuales que necesitas recordar est\u00e1n destinados a fallar eventualmente.</p> <ol> <li> <p>Noble WS (2009) A Quick Guide to Organizing Computational Biology Projects. PLOS Computational Biology 5(7): e1000424. https://doi.org/10.1371/journal.pcbi.1000424\u00a0\u21a9</p> </li> </ol>"},{"location":"content/next-steps/","title":"Github Pages","text":"<p>Hosting y herramientas de desarrollo web gratis</p> <p>Websites for you and your projects. Hosted directly from your GitHub repository. Just edit, push, and your changes are live.</p>"},{"location":"content/next-steps/#github-actions","title":"Github Actions","text":"<p>Automatizaci\u00f3n impresionante</p> <p>Automate your workflow from idea to production GitHub Actions makes it easy to automate all your software workflows, now with world-class CI/CD. Build, test, and deploy your code right from GitHub. Make code reviews, branch management, and issue triaging work the way you want.</p>"},{"location":"content/next-steps/#otras-formas-de-contar-esta-historia","title":"Otras formas de contar esta historia","text":"<p>Nbdev</p> <p>Create delightful software with Jupyter Notebooks Write, test, document, and distribute software packages and technical articles \u2014 all in one place, your notebook.</p>"},{"location":"cookbook/","title":"Cookbook","text":"<p>Example</p> System ASystem BSystem CSystem D <pre><code>* Sed sagittis eleifend rutrum\n* Donec vitae suscipit est\n* Nulla tempor lobortis orci\n</code></pre> <pre><code>1. Sed sagittis eleifend rutrum\n2. Donec vitae suscipit est\n3. Nulla tempor lobortis orci\n</code></pre> <pre><code>1. Sed sagittis eleifend rutrum\n2. Donec vitae suscipit est\n3. Nulla tempor lobortis orci\n</code></pre> <pre><code>1. Sed sagittis eleifend rutrum\n2. Donec vitae suscipit est\n3. Nulla tempor lobortis orci\n</code></pre>"},{"location":"instructor/","title":"2024","text":""},{"location":"instructor/#alonso-astroza","title":"Alonso Astroza","text":"<ul> <li>Soy Subdirector de Alianzas con Empresas en el Instituto de Ciencia de Datos de la Universidad del Desarrollo.</li> <li>Contribuyo en:<ul> <li>GeoVictoria</li> <li>Defontana</li> <li>Discolab</li> <li>Subconscious.ai</li> </ul> </li> <li>Ense\u00f1o en el Magister de Ciencia de Datos en la Universidad del Desarrollo.</li> <li>Ingeniero El\u00e9ctrico de la Universidad de Chile.</li> </ul>"},{"location":"instructor/#contacto","title":"Contacto","text":"<ul> <li> alonsoastroza@udd.cl</li> <li> aastroza</li> <li> aastrozacl</li> <li> aastroza</li> </ul>"},{"location":"instructor/#versiones","title":"Versiones","text":"<p>Dict\u00e9 el curso en las siguientes ocasiones:</p> <ul> <li>El 17 de enero del 2024 en el marco de la Escuela de Verano del CICS UDD.</li> <li>El 31 de mayo de 2024 en una sesi\u00f3n de trabajo del CRiSS Lab.</li> </ul>"},{"location":"material/","title":"Material de Clases","text":""},{"location":"material/#para-trabajar-durante-la-sesion","title":"Para trabajar durante la sesi\u00f3n","text":"<ul> <li>Template: IDS Cookiecutter</li> <li>Template: Introduccion a Github</li> </ul>"},{"location":"material/#ejemplos","title":"Ejemplos","text":"<ul> <li>Proyecto: Survey-it</li> <li>Template: Sitio del Curso</li> <li>Proyecto: Humor Chileno</li> </ul>"},{"location":"video/","title":"Grabaciones de Clases","text":""},{"location":"video/#31-de-mayo-de-2024","title":"31 de Mayo de 2024","text":"<p>Clase dictada durante una sesi\u00f3n de trabajo del CRiSS Lab.</p>"}]}